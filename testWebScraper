import requests
from bs4 import BeautifulSoup

# Step 1: Extract text from a webpage
def extract_text_from_url(url):
    response = requests.get(url)
    if response.status_code != 200:
        print(f"Failed to fetch the webpage: {response.status_code}")
        return None
    
    soup = BeautifulSoup(response.text, "html.parser")
    
    # Extract text from paragraphs
    paragraphs = [p.get_text() for p in soup.find_all("p")]
    
    # Join all text into a single string
    return "\n".join(paragraphs)

# Step 2: Summarize using ChatGPT API
def summarize_text(text):
    api_url = "https://api.openai.com/v1/chat/completions"  # OpenAI API endpoint
    api_key = "YOUR_OPENAI_API_KEY"  # Replace with your API key
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "gpt-4-turbo",  # Use GPT-4 for better summaries
        "messages": [
            {"role": "system", "content": "You are an AI assistant that summarizes text."},
            {"role": "user", "content": f"Summarize the following text:\n\n{text}"}
        ],
        "max_tokens": 300
    }
    
    response = requests.post(api_url, headers=headers, json=data)
    
    if response.status_code == 200:
        return response.json()["choices"][0]["message"]["content"]
    else:
        print(f"Error: {response.status_code}, {response.text}")
        return None

# Step 3: Test with a website
url = "https://en.wikipedia.org/wiki/Artificial_intelligence"  # Example website
text = extract_text_from_url(url)

if text:
    summary = summarize_text(text)
    if summary:
        print("\nSummary:\n", summary)